<!doctype html>
<html lang="en">
<head>
<title>Reinforcement Learning for Sensory Inputs</title>
<meta property="og:title" content=Reinforcement Learning for Sensory Inputs" />
<meta name="twitter:title" content="Reinforcement Learning for Sensory Inputs" />
<meta name="description" content="An Analysis of Playing Atari with Deep Reinforcement Learning." />
<meta property="og:description" content="An Analysis of Playing Atari with Deep Reinforcement Learning." />
<meta name="twitter:description" content="An Analysis of Playing Atari with Deep Reinforcement Learning." />
<meta property="og:type" content="website" />
<meta name="twitter:card" content="summary" /> 
<meta name="viewport" content="width=device-width,initial-scale=1" />
<!-- bootstrap for mobile-friendly layout -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.2/dist/css/bootstrap.min.css" integrity="sha384-xOolHFLEh07PJGoPkLv1IbcEPTNtaed2xpHsD9ESMhqIYd0nLMwNLD69Npy4HI+N" crossorigin="anonymous">
<script src="https://cdn.jsdelivr.net/npm/jquery@3.5.1/dist/jquery.slim.min.js" integrity="sha384-DfXdz2htPH0lsSSs5nCTpuj/zy4C+OGpamoFVy38MVBnE+IbbVYUew+OrCXaRkfj" crossorigin="anonymous"></script>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.2/dist/js/bootstrap.bundle.min.js" integrity="sha384-Fy6S3B9q64WdZWQUiU+q4/2Lc9npb8tCaSX9FK7E8HnRr0Jz8D6OP9dO5Vg3Q9ct" crossorigin="anonymous"></script>
<link href="https://fonts.googleapis.com/css?family=Open+Sans:300,400,700" rel="stylesheet">
<link href="style.css" rel="stylesheet">

</head>
<body class="nd-docs">
<div class="nd-pageheader">
 <div class="container">
 <h1 class="lead">
 <nobr class="widenobr">Playing Atari With Deep Reinforcement Learning</nobr>
 <nobr class="widenobr">For CS 7150</nobr>
 </h1>
 </div>
</div><!-- end nd-pageheader -->

<div class="container">
<div class="row">
<div class="col justify-content-center text-center">
<h2>An Analysis of Playing Atari With Deep Reinforcement Learning</h2>
<p>Revolutionizing the field of Reinforcement Learning by combining existing methods with Deep Learning networks on raw sensory input.</p>
</div>
</div>
<div class="row">
<div class="col">

<h2>Paper Overview</h2>
<p>The 2013 research paper "Playing Atari with Deep Reinforcement Learning" by Volodymyr Mnih and colleagues at DeepMind Technologies introduces a groundbreaking deep learning model. This model, a convolutional neural network, uses reinforcement learning to learn control policies directly from high-dimensional sensory inputs, specifically raw pixels from Atari 2600 games. The significance of this work lies in its demonstration of an AI system learning and performing at or above human level without needing manual feature extraction, representing a major advancement in AI capabilities.</p>

<h2>Literature Review</h2>
<p>The development of deep reinforcement learning, as showcased in this paper, is built upon earlier significant works. Pioneering algorithms like TD-gammon by Gerald Tesauro and Neural Fitted Q-learning (NFQ) by Martin Riedmiller laid the groundwork for this field. Additionally, the Arcade Learning Environment, developed by Marc Bellemare and others, provided a standard testing platform for reinforcement learning algorithms on Atari 2600 games. These foundational works were crucial for the advancements made in "Playing Atari with Deep Reinforcement Learning."</p>

<h2>Methodology and Technical Details</h2>
<p>The cornerstone of the research presented in "Playing Atari with Deep Reinforcement Learning" is its innovative network architecture. The model is a convolutional neural network (CNN), designed specifically to process and interpret the visual input from Atari games.</p>
<img src="https://media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fnature14236/MediaObjects/41586_2015_BFnature14236_Fig1_HTML.jpg?as=webp" alt="Network Architecture Diagram" style="display: block; margin: auto;">
<p>The architecture comprises three convolutional layers and two fully connected layers. The network processes input in the form of an 84x84x4 image, which is derived from preprocessing the raw frames of Atari 2600 games. Here's a breakdown of the layers:</p>
<ul>
    <li><strong>First Hidden Layer:</strong> This layer applies 16 8x8 filters with a stride of 4 to the input image. Following the convolution, a rectifier nonlinearity is applied.</li>
    <li><strong>Second Hidden Layer:</strong> This layer consists of 32 4x4 filters with a stride of 2, again followed by a rectifier nonlinearity.</li>
    <li><strong>Third Hidden Layer:</strong> The final hidden layer is fully connected, containing 256 rectifier units.</li>
    <li><strong>Output Layer:</strong> The output is a fully-connected linear layer, corresponding to each valid action in the game. The number of valid actions varies between 4 and 18, depending on the game.</li>
</ul>

<h2>Biography</h2>
<table>
    <tr>
        <td><img src="https://iu35-prod.s3.amazonaws.com/images/volodymyr.mnih.width-1360.jpg" alt="Volodymyr Mnih" style="width:100px;height:100px;"></td>
        <td>Volodymyr Mnih: PhD in Machine Learning from the University of Toronto and a Master's degree in computing science from the University of Alberta.</td>
    </tr>
    <tr>
        <td><img src="https://media.licdn.com/dms/image/C4E03AQH5ht8QO2oyUw/profile-displayphoto-shrink_200_200/0/1572371487626?e=1707350400&v=beta&t=78UnmP1Ey7L9HNvijnVIZCfiRmOIwphHeqfswuPnUaA" alt="Koray Kavukcuoglu" style="width:100px;height:100px;"></td>
        <td>Koray Kavukcuoglu: VP of Research at DeepMind, previously at NEC Labs America. PhD from New York University, with a background in aerospace engineering.</td>
    </tr>
    <tr>
        <td><img src="https://www.davidsilver.uk/wp-content/uploads/2020/03/Dave_Silver_Headshot.jpg" alt="David Silver" style="width:100px;height:100px;"></td>
        <td>David Silver: Principal Research Scientist at DeepMind and professor at University College London, contributing significantly to AI research.</td>
    </tr>
    <tr>
        <td><img src="https://www.cs.toronto.edu/~graves/pic.jpg" alt="Alex Graves" style="width:100px;height:100px;"></td>
        <td>Alex Graves: Research Scientist at DeepMind, holding a BSc in Theoretical Physics from the University of Edinburgh and a PhD in artificial intelligence.</td>
    </tr>
    <tr>
        <td><img src="https://www.chessprogramming.org/images/f/fb/IoannisAntonoglou.jpg" alt="Ioannis Antonoglou" style="width:100px;height:100px;"></td>
        <td>Ioannis Antonoglou: Software Engineer at Google DeepMind, with an engineer's degree in electrical and computer engineering and an M.Sc. in artificial intelligence and machine learning.</td>
    </tr>
    <tr>
        <td><img src="https://images.nrc.nl/FTMR6sDLGwzm1DERf6PQj64wq5I=/1920x/filters:no_upscale():format(webp)/s3/static.nrc.nl/images/stripped/1006hgv_voorfoto.jpg" alt="Daan Wierstra" style="width:100px;height:100px;"></td>
        <td>Daan Wierstra: Principal Scientist at DeepMind, specializing in scientific roles and research in AI.</td>
    </tr>
    <tr>
        <td><img src="https://argmax.ai/images/speakers/riedmiller.jpg" alt="Martin Riedmiller" style="width:100px;height:100px;"></td>
        <td>Martin Riedmiller: Team Lead at DeepMind, focused on the development of intelligent machines learning new concepts autonomously.</td>
    </tr>
</table>

<h2>Social Impact</h2>
<p>The method presented in the paper has far-reaching implications for society. Positively, it opens avenues in robotics, autonomous vehicles, and advanced gaming systems. However, it also raises concerns about its potential use in autonomous weapons systems and gambling, which could have detrimental societal impacts. The ability of these models to learn and operate autonomously in complex environments is both an opportunity and a challenge for ethical considerations in technology development.</p>

<h2>Industry Applications</h2>
<p>The method detailed in this paper has practical applications in the development of AI and robotics, particularly in systems that require autonomous decision-making based on sensory inputs. Its application in self-driving cars is a notable example, showcasing its potential in enhancing decision-making processes in autonomous systems.</p>

<h2>Follow-on Research</h2>
<p>The paper lays the foundation for further research in applying deep reinforcement learning to more complex and contemporary games. This progression from Atari games to more sophisticated gaming environments can provide deeper insights and more robust applications of AI in various fields.</p>

<h2>Peer-Review</h2>

<p>Just as we have done in the role-playing exercise, analyze the paper from all perspectives.
</p>

<h2>References</h2>
<ul>
    <li><a href="https://www.cs.toronto.edu/~vmnih/docs/dqn.pdf">Mnih, V., et al. (2013). <em>Playing Atari with Deep Reinforcement Learning</em>. NIPS Deep Learning Workshop, 2013.</a></li>
    <li><a href="https://dl.acm.org/doi/10.1145/203330.203343">Tesauro, G. (1995). <em>TD-Gammon: A Self-Teaching Backgammon Program</em>. Semantic Scholar.</a></li>
    <li><a href="https://www.semanticscholar.org/paper/Neural-Fitted-Q-Iteration-First-Experiences-with-a-Riedmiller/282001869bd502c7917db8b32b75593addfbbc68">Riedmiller, M. (2005). <em>Neural Fitted Q Iteration - First Experiences with a Data Efficient Neural Reinforcement Learning Method</em>. Semantic Scholar.</a></li>
    <li><a href="https://ar5iv.org/abs/1207.4708">Bellemare, M., et al. <em>The Arcade Learning Environment: An Evaluation Platform for General Agents</em>. Ar5iv.</a></li>
</ul>

<h2>Team Members</h2>                                       
<p>Chase Kenyon, Nicholas Calvaresi.</p>

  
</div><!--col-->
</div><!--row -->
</div> <!-- container -->

<footer class="nd-pagefooter">
  <div class="row">
    <div class="col-6 col-md text-center">
      <a href="https://cs7150.baulab.info/">About CS 7150</a>
    </div>
  </div>
</footer>

</body>
<script>
$(document).on('click', '.clickselect', function(ev) {
  var range = document.createRange();
  range.selectNodeContents(this);
  var sel = window.getSelection();
  sel.removeAllRanges();
  sel.addRange(range);
});
// Google analytics below.
window.dataLayer = window.dataLayer || [];
</script>
</html>
